# ğŸ–ï¸ Hand Detection with Landmarks

A PyTorch-based deep learning project focused on detecting multiple hands in an image and predicting precise landmark keypoints for each hand. This repository serves as a foundational module for gesture recognition, sign language translation, and human-computer interaction systems.

---

## ğŸš€ Features

- ğŸ” **Multi-hand detection** capability
- ğŸ¯ **21 keypoint landmark localization** per detected hand
- ğŸ“¦ **Modular dataset loader**, currently tailored for the [FreiHAND dataset](https://lmb.informatik.uni-freiburg.de/projects/freihand/).
- ğŸ’¾ **Validation & checkpointing** integrated
- ğŸ† **Supports augmentation handling and custom training splits**
- ğŸ”¥ Designed for **real-time extensions and downstream tasks**

---

## ğŸ—‚ï¸ Project Structure
```
hand-detection-landmarks/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ freihand_dataset.py        # Custom Dataset class for FreiHAND
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ hand_landmark_model.py     # Model architecture definition
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ preprocessing.py           # 3D to 2D keypoint projection, helpers
â”‚   â”œâ”€â”€ config/
â”‚   â””â”€â”€ params.py                      # Hyperparameters & file paths
â”‚   â”œâ”€â”€ train.py                       # Training loop
â”œâ”€â”€ checkpoints/                       # Saved model checkpoints (not included)
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ FreiHAND_pub_v2/               # Dataset folder (not included)
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ Quick Start

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/uzayyildiztaskan/Hand-Detection-Landmarks
cd Hand-Detection-Landmarks
```
### 2ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```
### 3ï¸âƒ£ Prepare Dataset
Download the FreiHAND dataset

Place files in:

```
dataset/FreiHAND_pub_v2/
```
### 4ï¸âƒ£ Train the Model
```
python -m src.train
```
### 5ï¸âƒ£ Checkpoints & Validation
Checkpoints are saved in ```/checkpoints/``` when validation loss improves. Configure validation split in ```config/params.py```.

### 5ï¸âƒ£ Inference
After specifying ```IMAGE_PATH``` and ```CHECKPOINT_PATH``` in ```inference.py``` run the script by
```
python -m src.inference
```

![Sample image inference from dataset](https://github.com/uzayyildiztaskan/Hand-Detection-Landmarks/blob/main/inference_images/Figure_1.png)

Infered model parameters:

* Epochs: ```15```
* Layers Unfreezed: ```6```
* Train Loss: ```10.9017```, Val Loss: ```14.3914```
* Train IoU: ```0.8973```, Val IoU: ```0.8919```
* Train PCK: ```0.9942```, Val PCK: ```0.9826```
* ALPHA: ```1.0```
* BETA: ```1.0```
* Margin of bounding box: ```0```

---

## ğŸ“Œ Future Work

* Sign language translation pipeline integration

* Real-time inference demo (OpenCV/Streamlit)

---

## ğŸ“œ License
MIT License - see [LICENSE](https://github.com/uzayyildiztaskan/Hand-Detection-Landmarks/blob/main/LICENSE) for details.
